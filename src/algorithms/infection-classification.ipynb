{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1a092538f800be1",
   "metadata": {},
   "source": [
    "# Tests of different classifiers – INFECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80cecbc4104811b",
   "metadata": {},
   "source": [
    "# OCPC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa62f187daa9c3",
   "metadata": {},
   "source": [
    "## OCPC with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54540b263e01e5fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T20:29:55.434131Z",
     "start_time": "2025-09-01T20:28:30.593840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Cross-Validation - Training]\n",
      "\n",
      "[Fold 1]\n",
      "Accuracy: 0.5302 | Precision: 0.5241 | Recall: 0.4914 | F1: 0.5072 | AUC: 0.5676\n",
      "\n",
      "[Fold 2]\n",
      "Accuracy: 0.5493 | Precision: 0.5533 | Recall: 0.5169 | F1: 0.5345 | AUC: 0.5746\n",
      "\n",
      "[Fold 3]\n",
      "Accuracy: 0.5372 | Precision: 0.5177 | Recall: 0.5177 | F1: 0.5177 | AUC: 0.5577\n",
      "\n",
      "[Fold 4]\n",
      "Accuracy: 0.5361 | Precision: 0.5451 | Recall: 0.5417 | F1: 0.5434 | AUC: 0.5371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 14:34:49] Multiple instances of codecarbon are allowed to run at the same time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold 5]\n",
      "Accuracy: 0.5605 | Precision: 0.5801 | Recall: 0.5492 | F1: 0.5642 | AUC: 0.5896\n",
      "\n",
      "[Average Metrics - Cross-Validation]\n",
      "Accuracy: 0.5427 ± 0.0109\n",
      "Precision: 0.5441 ± 0.0223\n",
      "Recall:   0.5234 ± 0.0205\n",
      "F1-Score: 0.5334 ± 0.0199\n",
      "AUC:      0.5653 ± 0.0175\n",
      "\n",
      "[Final Training and Test Evaluation]\n",
      "\n",
      "[Carbon Footprint]\n",
      "Estimated emissions during the experiment: 0.000020 kg CO₂eq\n",
      "\n",
      "[Test Set Performance]\n",
      "Accuracy: 0.5501\n",
      "Precision: 0.5543\n",
      "Recall:   0.5110\n",
      "F1-Score: 0.5318\n",
      "AUC:      0.5817\n",
      "Confusion Matrix:\n",
      "[[347 242]\n",
      " [288 301]]\n",
      "\n",
      "[Inference Time]\n",
      "Average time per image: 0.000416 s ± 0.001845 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/infection\\\\OCPC_model.pkl']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from ocpc_py import MultiClassPC\n",
    "from codecarbon import EmissionsTracker\n",
    "import json\n",
    "\n",
    "# DATA LOADING\n",
    "base_path = \"../data/infection\"\n",
    "image_size = (256, 256)\n",
    "\n",
    "dataset = []\n",
    "for class_name, label in zip([\"Aug-Positive\", \"Aug-Negative\"], [1, 0]):\n",
    "    folder = os.path.join(base_path, class_name)\n",
    "    for image_name in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, image_name)\n",
    "        dataset.append((image_path, label))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=[\"image\", \"label\"])\n",
    "\n",
    "# Load, resize, normalize, and flatten images\n",
    "def load_images(df, image_size):\n",
    "    images, labels = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        img = cv2.imread(row[\"image\"])\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, image_size)\n",
    "            img = img.astype(\"float32\") / 255.0\n",
    "            images.append(img.flatten())\n",
    "            labels.append(row[\"label\"])\n",
    "        else:\n",
    "            print(f\"Image not loaded: {row['image']}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_all, y_all = load_images(df, image_size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "# CROSS-VALIDATION\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "\n",
    "print(\"\\n[Cross-Validation - Training]\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    svd = TruncatedSVD(n_components=50, random_state=80)\n",
    "    X_tr_svd = svd.fit_transform(X_tr)\n",
    "    X_val_svd = svd.transform(X_val)\n",
    "\n",
    "    clf = MultiClassPC()\n",
    "    clf.fit(X_tr_svd, y_tr)\n",
    "    y_pred = clf.predict(X_val_svd)\n",
    "    y_proba = clf.predict_proba(X_val_svd)[:, 1]\n",
    "\n",
    "    accs.append(accuracy_score(y_val, y_pred))\n",
    "    precs.append(precision_score(y_val, y_pred))\n",
    "    recs.append(recall_score(y_val, y_pred))\n",
    "    f1s.append(f1_score(y_val, y_pred))\n",
    "    aucs.append(roc_auc_score(y_val, y_proba))\n",
    "\n",
    "    print(f\"\\n[Fold {fold}]\")\n",
    "    print(f\"Accuracy: {accs[-1]:.4f} | Precision: {precs[-1]:.4f} | Recall: {recs[-1]:.4f} | F1: {f1s[-1]:.4f} | AUC: {aucs[-1]:.4f}\")\n",
    "\n",
    "# Final K-Fold Metrics\n",
    "print(\"\\n[Average Metrics - Cross-Validation]\")\n",
    "print(f\"Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "print(f\"Precision: {np.mean(precs):.4f} ± {np.std(precs):.4f}\")\n",
    "print(f\"Recall:   {np.mean(recs):.4f} ± {np.std(recs):.4f}\")\n",
    "print(f\"F1-Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "print(f\"AUC:      {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
    "\n",
    "# Final training and test evaluation\n",
    "print(\"\\n[Final Training and Test Evaluation]\")\n",
    "tracker = EmissionsTracker(log_level=\"ERROR\")\n",
    "tracker.start()\n",
    "\n",
    "# Final SVD\n",
    "svd_final = TruncatedSVD(n_components=50, random_state=80)\n",
    "X_train_svd = svd_final.fit_transform(X_train)\n",
    "X_test_svd = svd_final.transform(X_test)\n",
    "\n",
    "# Final Classifier Training\n",
    "clf_final = MultiClassPC()\n",
    "clf_final.fit(X_train_svd, y_train)\n",
    "\n",
    "# Stop tracker and save emissions\n",
    "emissions = tracker.stop()\n",
    "\n",
    "# Emissions\n",
    "emissions_dir = \"../reports/emissions\"\n",
    "os.makedirs(emissions_dir, exist_ok=True)\n",
    "emissions_path = os.path.join(emissions_dir, \"emissions_infection.json\")\n",
    "with open(emissions_path, \"w\") as f:\n",
    "    json.dump({\"emissions_kgCO2eq\": emissions}, f)\n",
    "\n",
    "print(f\"\\n[Carbon Footprint]\")\n",
    "print(f\"Estimated emissions during the experiment: {emissions:.6f} kg CO₂eq\")\n",
    "\n",
    "# Test set evaluation\n",
    "y_pred_test = clf_final.predict(X_test_svd)\n",
    "y_proba_test = clf_final.predict_proba(X_test_svd)[:, 1]\n",
    "\n",
    "print(\"\\n[Test Set Performance]\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall:   {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"AUC:      {roc_auc_score(y_test, y_proba_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Measuring Inference Time\n",
    "inference_times = []\n",
    "for x in X_test_svd:\n",
    "    start = time.time()\n",
    "    _ = clf_final.predict(x.reshape(1, -1))\n",
    "    end = time.time()\n",
    "    inference_times.append(end - start)\n",
    "\n",
    "inference_times = np.array(inference_times)\n",
    "print(\"\\n[Inference Time]\")\n",
    "print(f\"Average time per image: {np.mean(inference_times):.6f} s ± {np.std(inference_times):.6f} s\")\n",
    "\n",
    "# Save SVD and Model\n",
    "output_dir = \"../models/infection\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "svd_path = os.path.join(output_dir, \"OCPC_svd.pkl\")\n",
    "clf_path = os.path.join(output_dir, \"OCPC_model.pkl\")\n",
    "joblib.dump(svd_final, svd_path)\n",
    "joblib.dump(clf_final, clf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7f0accee0cb44f",
   "metadata": {},
   "source": [
    "## OCPC with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0219ced451bf178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T15:53:20.943470Z",
     "start_time": "2025-09-02T15:52:07.495747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Cross-Validation - Training]\n",
      "\n",
      "[Fold 1]\n",
      "Accuracy: 0.5292 | Precision: 0.5245 | Recall: 0.4612 | F1: 0.4908 | AUC: 0.5654\n",
      "\n",
      "[Fold 2]\n",
      "Accuracy: 0.5493 | Precision: 0.5535 | Recall: 0.5148 | F1: 0.5335 | AUC: 0.5740\n",
      "\n",
      "[Fold 3]\n",
      "Accuracy: 0.5531 | Precision: 0.5358 | Recall: 0.5133 | F1: 0.5243 | AUC: 0.5731\n",
      "\n",
      "[Fold 4]\n",
      "Accuracy: 0.5329 | Precision: 0.5444 | Recall: 0.5104 | F1: 0.5269 | AUC: 0.5377\n",
      "\n",
      "[Fold 5]\n",
      "Accuracy: 0.5817 | Precision: 0.6044 | Recall: 0.5574 | F1: 0.5800 | AUC: 0.6038\n",
      "\n",
      "[Average Metrics - Cross-Validation]\n",
      "Accuracy: 0.5492 ± 0.0187\n",
      "Precision: 0.5525 ± 0.0277\n",
      "Recall:   0.5114 ± 0.0305\n",
      "F1-Score: 0.5311 ± 0.0286\n",
      "AUC:      0.5708 ± 0.0211\n",
      "\n",
      "[Final Training and Test Evaluation]\n",
      "\n",
      "[Carbon Footprint]\n",
      "Estimated emissions during the experiment: 0.000036 kg CO₂eq\n",
      "\n",
      "[Test Set Performance]\n",
      "Accuracy: 0.5407\n",
      "Precision: 0.5465\n",
      "Recall:   0.4788\n",
      "F1-Score: 0.5104\n",
      "AUC:      0.5716\n",
      "Confusion Matrix:\n",
      "[[355 234]\n",
      " [307 282]]\n",
      "\n",
      "[Inference Time]\n",
      "Average time per image: 0.001173 s ± 0.002565 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/infection\\\\OCPC_pca_model_infection.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from ocpc_py import MultiClassPC\n",
    "from codecarbon import EmissionsTracker\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "base_path = \"../data/infection\"\n",
    "image_size = (256, 256)\n",
    "\n",
    "# Load dataset\n",
    "dataset = []\n",
    "for class_name, label in zip([\"Aug-Positive\", \"Aug-Negative\"], [1, 0]):\n",
    "    folder = os.path.join(base_path, class_name)\n",
    "    for image_name in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, image_name)\n",
    "        dataset.append((image_path, label))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=[\"image\", \"label\"])\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(df, image_size):\n",
    "    images, labels = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        img = cv2.imread(row[\"image\"])\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, image_size)\n",
    "            img = img.astype(\"float32\") / 255.0\n",
    "            images.append(img.flatten())\n",
    "            labels.append(row[\"label\"])\n",
    "        else:\n",
    "            print(f\"Image not loaded: {row['image']}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_all, y_all = load_images(df, image_size)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "\n",
    "print(\"\\n[Cross-Validation - Training]\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # PCA transformation\n",
    "    pca = PCA(n_components=50)\n",
    "    X_tr_pca = pca.fit_transform(X_tr)\n",
    "    X_val_pca = pca.transform(X_val)\n",
    "\n",
    "    # Train classifier\n",
    "    clf = MultiClassPC()\n",
    "    clf.fit(X_tr_pca, y_tr)\n",
    "    y_pred = clf.predict(X_val_pca)\n",
    "    y_proba = clf.predict_proba(X_val_pca)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    accs.append(accuracy_score(y_val, y_pred))\n",
    "    precs.append(precision_score(y_val, y_pred))\n",
    "    recs.append(recall_score(y_val, y_pred))\n",
    "    f1s.append(f1_score(y_val, y_pred))\n",
    "    aucs.append(roc_auc_score(y_val, y_proba))\n",
    "\n",
    "    print(f\"\\n[Fold {fold}]\")\n",
    "    print(f\"Accuracy: {accs[-1]:.4f} | Precision: {precs[-1]:.4f} | Recall: {recs[-1]:.4f} | F1: {f1s[-1]:.4f} | AUC: {aucs[-1]:.4f}\")\n",
    "\n",
    "# Average metrics across folds\n",
    "print(\"\\n[Average Metrics - Cross-Validation]\")\n",
    "print(f\"Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "print(f\"Precision: {np.mean(precs):.4f} ± {np.std(precs):.4f}\")\n",
    "print(f\"Recall:   {np.mean(recs):.4f} ± {np.std(recs):.4f}\")\n",
    "print(f\"F1-Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "print(f\"AUC:      {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
    "\n",
    "# Final training and test evaluation\n",
    "print(\"\\n[Final Training and Test Evaluation]\")\n",
    "tracker = EmissionsTracker(log_level=\"ERROR\")\n",
    "tracker.start()\n",
    "\n",
    "# Final PCA transformation\n",
    "pca_final = PCA(n_components=50)\n",
    "X_train_pca = pca_final.fit_transform(X_train)\n",
    "X_test_pca = pca_final.transform(X_test)\n",
    "\n",
    "# Train final classifier\n",
    "clf_final = MultiClassPC()\n",
    "clf_final.fit(X_train_pca, y_train)\n",
    "\n",
    "# Stop carbon tracker and save emissions\n",
    "emissions = tracker.stop()\n",
    "emissions_dir = \"../reports/emissions\"\n",
    "os.makedirs(emissions_dir, exist_ok=True)\n",
    "emissions_path = os.path.join(emissions_dir, \"emissions_infection.json\")\n",
    "with open(emissions_path, \"w\") as f:\n",
    "    json.dump({\"emissions_kgCO2eq\": emissions}, f)\n",
    "\n",
    "print(f\"\\n[Carbon Footprint]\")\n",
    "print(f\"Estimated emissions during the experiment: {emissions:.6f} kg CO₂eq\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test = clf_final.predict(X_test_pca)\n",
    "y_proba_test = clf_final.predict_proba(X_test_pca)[:, 1]\n",
    "\n",
    "print(\"\\n[Test Set Performance]\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall:   {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"AUC:      {roc_auc_score(y_test, y_proba_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Measure inference time\n",
    "inference_times = []\n",
    "for x in X_test_pca:\n",
    "    start = time.time()\n",
    "    _ = clf_final.predict(x.reshape(1, -1))\n",
    "    end = time.time()\n",
    "    inference_times.append(end - start)\n",
    "\n",
    "inference_times = np.array(inference_times)\n",
    "print(\"\\n[Inference Time]\")\n",
    "print(f\"Average time per image: {np.mean(inference_times):.6f} s ± {np.std(inference_times):.6f} s\")\n",
    "\n",
    "# Save PCA and final model\n",
    "output_dir = \"../models/infection\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "pca_path = os.path.join(output_dir, \"OCPC_pca_infection.pkl\")\n",
    "clf_path = os.path.join(output_dir, \"OCPC_pca_model_infection.pkl\")\n",
    "joblib.dump(pca_final, pca_path)\n",
    "joblib.dump(clf_final, clf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54631a0",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec985eb0",
   "metadata": {},
   "source": [
    "## Randon Forest without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf18d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Cross-Validation - Training]\n",
      "\n",
      "[Fold 1]\n",
      "Accuracy: 0.7370 | Precision: 0.7596 | Recall: 0.6810 | F1: 0.7182 | AUC: 0.8123\n",
      "\n",
      "[Fold 2]\n",
      "Accuracy: 0.7285 | Precision: 0.7741 | Recall: 0.6462 | F1: 0.7044 | AUC: 0.8101\n",
      "\n",
      "[Fold 3]\n",
      "Accuracy: 0.7537 | Precision: 0.7535 | Recall: 0.7235 | F1: 0.7381 | AUC: 0.8324\n",
      "\n",
      "[Fold 4]\n",
      "Accuracy: 0.7304 | Precision: 0.7580 | Recall: 0.6917 | F1: 0.7233 | AUC: 0.7999\n",
      "\n",
      "[Fold 5]\n",
      "Accuracy: 0.7176 | Precision: 0.7523 | Recall: 0.6783 | F1: 0.7134 | AUC: 0.8112\n",
      "\n",
      "[Average Metrics - Cross-Validation]\n",
      "Accuracy: 0.7334 ± 0.0119\n",
      "Precision: 0.7595 ± 0.0078\n",
      "Recall:   0.6841 ± 0.0248\n",
      "F1-Score: 0.7195 ± 0.0112\n",
      "AUC:      0.8132 ± 0.0106\n",
      "\n",
      "[Final Training and Test Evaluation]\n",
      "\n",
      "[Carbon Footprint]\n",
      "Estimated emissions during training: 0.000050 kg CO₂eq\n",
      "\n",
      "[Test Set Performance]\n",
      "Accuracy: 0.7445\n",
      "Precision: 0.7717\n",
      "Recall:   0.6944\n",
      "F1-Score: 0.7310\n",
      "AUC:      0.8168\n",
      "Confusion Matrix:\n",
      "[[468 121]\n",
      " [180 409]]\n",
      "\n",
      "[Inference Time]\n",
      "Average time per image: 0.027872 s ± 0.004010 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/infection\\\\random_forest_infection.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "import joblib\n",
    "from codecarbon import EmissionsTracker\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "base_path = \"../data/infection\"\n",
    "image_size = (256, 256)\n",
    "\n",
    "# Load dataset\n",
    "dataset = []\n",
    "for class_name, label in zip([\"Aug-Positive\", \"Aug-Negative\"], [1, 0]):\n",
    "    folder = os.path.join(base_path, class_name)\n",
    "    for image_name in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, image_name)\n",
    "        dataset.append((image_path, label))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=[\"image\", \"label\"])\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(df, image_size):\n",
    "    images, labels = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        img = cv2.imread(row[\"image\"])\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, image_size)\n",
    "            img = img.astype(\"float32\") / 255.0\n",
    "            images.append(img.flatten())\n",
    "            labels.append(row[\"label\"])\n",
    "        else:\n",
    "            print(f\"Image not loaded: {row['image']}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_all, y_all = load_images(df, image_size)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "\n",
    "print(\"\\n[Cross-Validation - Training]\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # Train Random Forest classifier\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=20,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    y_pred = clf.predict(X_val)\n",
    "    y_proba = clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Compute metrics\n",
    "    accs.append(accuracy_score(y_val, y_pred))\n",
    "    precs.append(precision_score(y_val, y_pred))\n",
    "    recs.append(recall_score(y_val, y_pred))\n",
    "    f1s.append(f1_score(y_val, y_pred))\n",
    "    aucs.append(roc_auc_score(y_val, y_proba))\n",
    "\n",
    "    print(f\"\\n[Fold {fold}]\")\n",
    "    print(f\"Accuracy: {accs[-1]:.4f} | Precision: {precs[-1]:.4f} | Recall: {recs[-1]:.4f} | F1: {f1s[-1]:.4f} | AUC: {aucs[-1]:.4f}\")\n",
    "\n",
    "# Average metrics across folds\n",
    "print(\"\\n[Average Metrics - Cross-Validation]\")\n",
    "print(f\"Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "print(f\"Precision: {np.mean(precs):.4f} ± {np.std(precs):.4f}\")\n",
    "print(f\"Recall:   {np.mean(recs):.4f} ± {np.std(recs):.4f}\")\n",
    "print(f\"F1-Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "print(f\"AUC:      {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
    "\n",
    "# Final training and test evaluation\n",
    "print(\"\\n[Final Training and Test Evaluation]\")\n",
    "tracker = EmissionsTracker(log_level=\"ERROR\")\n",
    "tracker.start()\n",
    "\n",
    "clf_final = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=20,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf_final.fit(X_train, y_train)\n",
    "\n",
    "# Stop carbon tracker and save emissions\n",
    "emissions = tracker.stop()\n",
    "emissions_dir = \"../reports/emissions\"\n",
    "os.makedirs(emissions_dir, exist_ok=True)\n",
    "emissions_path = os.path.join(emissions_dir, \"emissions_infection_rf.json\")\n",
    "with open(emissions_path, \"w\") as f:\n",
    "    json.dump({\"emissions_kgCO2eq\": emissions}, f)\n",
    "\n",
    "print(f\"\\n[Carbon Footprint]\")\n",
    "print(f\"Estimated emissions during training: {emissions:.6f} kg CO₂eq\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test = clf_final.predict(X_test)\n",
    "y_proba_test = clf_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n[Test Set Performance]\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall:   {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"AUC:      {roc_auc_score(y_test, y_proba_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Measure inference time\n",
    "inference_times = []\n",
    "for x in X_test:\n",
    "    start = time.time()\n",
    "    _ = clf_final.predict([x])\n",
    "    end = time.time()\n",
    "    inference_times.append(end - start)\n",
    "\n",
    "inference_times = np.array(inference_times)\n",
    "print(\"\\n[Inference Time]\")\n",
    "print(f\"Average time per image: {np.mean(inference_times):.6f} s ± {np.std(inference_times):.6f} s\")\n",
    "\n",
    "# Save final model\n",
    "output_dir = \"../models/infection\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "clf_path = os.path.join(output_dir, \"random_forest_infection.pkl\")\n",
    "joblib.dump(clf_final, clf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8abf274",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ece9e30",
   "metadata": {},
   "source": [
    "# Random Forest with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edeccee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Cross-Validation - Training]\n",
      "\n",
      "[Fold 1]\n",
      "Acurácia: 0.6978 | Precisão: 0.6808 | Recall: 0.7263 | F1: 0.7028 | AUC: 0.7655\n",
      "\n",
      "[Fold 2]\n",
      "Acurácia: 0.7020 | Precisão: 0.6985 | Recall: 0.7119 | F1: 0.7051 | AUC: 0.7798\n",
      "\n",
      "[Fold 3]\n",
      "Acurácia: 0.7240 | Precisão: 0.6853 | Recall: 0.7854 | F1: 0.7320 | AUC: 0.7886\n",
      "\n",
      "[Fold 4]\n",
      "Acurácia: 0.6847 | Precisão: 0.6819 | Recall: 0.7146 | F1: 0.6979 | AUC: 0.7584\n",
      "\n",
      "[Fold 5]\n",
      "Acurácia: 0.6794 | Precisão: 0.6816 | Recall: 0.7152 | F1: 0.6980 | AUC: 0.7695\n",
      "\n",
      "[Average Metrics - Cross-Validation]\n",
      "Accuracy: 0.6976 ± 0.0156\n",
      "Precision: 0.6856 ± 0.0066\n",
      "Recall:   0.7307 ± 0.0278\n",
      "F1-Score: 0.7072 ± 0.0127\n",
      "AUC:      0.7724 ± 0.0107\n",
      "\n",
      "[Final Training and Test Evaluation]\n",
      "\n",
      "[Carbon Footprint]\n",
      "Estimated emissions during training: 0.000023 kg CO₂eq\n",
      "\n",
      "[Test Set Performance]\n",
      "Accuracy: 0.7046\n",
      "Precision: 0.6922\n",
      "Recall:   0.7368\n",
      "F1-Score: 0.7138\n",
      "AUC:      0.7925\n",
      "Confusion Matrix:\n",
      "[[396 193]\n",
      " [155 434]]\n",
      "\n",
      "[Inference Time]\n",
      "Average time per image: 0.027961 s ± 0.004011 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/infection\\\\random_forest_modelo_PCA_infection.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from codecarbon import EmissionsTracker\n",
    "import joblib\n",
    "\n",
    "# Configuration\n",
    "base_path = \"../data/infection\"\n",
    "image_size = (256, 256)\n",
    "\n",
    "# Load dataset\n",
    "dataset = []\n",
    "for classe, label in zip([\"Aug-Positive\", \"Aug-Negative\"], [1, 0]):\n",
    "    pasta = os.path.join(base_path, classe)\n",
    "    for imagem in os.listdir(pasta):\n",
    "        caminho_imagem = os.path.join(pasta, imagem)\n",
    "        dataset.append((caminho_imagem, label))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=[\"imagem\", \"label\"])\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(df, image_size):\n",
    "    imagens, labels = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        img = cv2.imread(row[\"imagem\"])\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, image_size)\n",
    "            img = img.astype(\"float32\") / 255.0\n",
    "            imagens.append(img.flatten())\n",
    "            labels.append(row[\"label\"])\n",
    "        else:\n",
    "            print(f\"Imagem não carregada: {row['imagem']}\")\n",
    "    return np.array(imagens), np.array(labels)\n",
    "\n",
    "X_all, y_all = load_images(df, image_size)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "\n",
    "print(\"\\n[Cross-Validation - Training]\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    pca = PCA(n_components=50)\n",
    "    X_tr_pca = pca.fit_transform(X_tr)\n",
    "    X_val_pca = pca.transform(X_val)\n",
    "\n",
    "    # Train Random Forest classifier\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=20,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    clf.fit(X_tr_pca, y_tr)\n",
    "    y_pred = clf.predict(X_val_pca)\n",
    "    y_proba = clf.predict_proba(X_val_pca)[:, 1]\n",
    "\n",
    "    # Compute metrics\n",
    "    accs.append(accuracy_score(y_val, y_pred))\n",
    "    precs.append(precision_score(y_val, y_pred))\n",
    "    recs.append(recall_score(y_val, y_pred))\n",
    "    f1s.append(f1_score(y_val, y_pred))\n",
    "    aucs.append(roc_auc_score(y_val, y_proba))\n",
    "\n",
    "    print(f\"\\n[Fold {fold}]\")\n",
    "    print(f\"Acurácia: {accs[-1]:.4f} | Precisão: {precs[-1]:.4f} | Recall: {recs[-1]:.4f} | F1: {f1s[-1]:.4f} | AUC: {aucs[-1]:.4f}\")\n",
    "\n",
    "# Average metrics across folds\n",
    "print(\"\\n[Average Metrics - Cross-Validation]\")\n",
    "print(f\"Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "print(f\"Precision: {np.mean(precs):.4f} ± {np.std(precs):.4f}\")\n",
    "print(f\"Recall:   {np.mean(recs):.4f} ± {np.std(recs):.4f}\")\n",
    "print(f\"F1-Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "print(f\"AUC:      {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
    "\n",
    "# Final training and test evaluation\n",
    "print(\"\\n[Final Training and Test Evaluation]\")\n",
    "tracker = EmissionsTracker(log_level=\"ERROR\")\n",
    "tracker.start()\n",
    "\n",
    "pca_final = PCA(n_components=50)\n",
    "X_train_pca = pca_final.fit_transform(X_train)\n",
    "X_test_pca = pca_final.transform(X_test)\n",
    "\n",
    "clf_final = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=20,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf_final.fit(X_train_pca, y_train)\n",
    "\n",
    "# Stop carbon tracker and save emissions\n",
    "emissions = tracker.stop()\n",
    "emissions_dir = \"../reports/emissions\"\n",
    "os.makedirs(emissions_dir, exist_ok=True)\n",
    "emissions_path = os.path.join(emissions_dir, \"emissions_infection_rf.json\")\n",
    "with open(emissions_path, \"w\") as f:\n",
    "    json.dump({\"emissions_kgCO2eq\": emissions}, f)\n",
    "\n",
    "print(f\"\\n[Carbon Footprint]\")\n",
    "print(f\"Estimated emissions during training: {emissions:.6f} kg CO₂eq\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test = clf_final.predict(X_test_pca)\n",
    "y_proba_test = clf_final.predict_proba(X_test_pca)[:, 1]\n",
    "\n",
    "print(\"\\n[Test Set Performance]\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall:   {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"AUC:      {roc_auc_score(y_test, y_proba_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Measure inference time\n",
    "inference_times = []\n",
    "for x in X_test_pca:\n",
    "    start = time.time()\n",
    "    _ = clf_final.predict([x])\n",
    "    end = time.time()\n",
    "    inference_times.append(end - start)\n",
    "\n",
    "inference_times = np.array(inference_times)\n",
    "print(\"\\n[Inference Time]\")\n",
    "print(f\"Average time per image: {np.mean(inference_times):.6f} s ± {np.std(inference_times):.6f} s\")\n",
    "\n",
    "# Save final model\n",
    "output_dir = \"../models/infection\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "pca_path = os.path.join(output_dir, \"random_forest_PCA_infection.pkl\")\n",
    "clf_path = os.path.join(output_dir, \"random_forest_modelo_PCA_infection.pkl\")\n",
    "joblib.dump(pca_final, pca_path)\n",
    "joblib.dump(clf_final, clf_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1a092538f800be1",
   "metadata": {},
   "source": [
    "# Tests of different classifiers – INFECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80cecbc4104811b",
   "metadata": {},
   "source": [
    "# OCPC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7f0accee0cb44f",
   "metadata": {},
   "source": [
    "## OCPC with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0219ced451bf178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T15:53:20.943470Z",
     "start_time": "2025-09-02T15:52:07.495747Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from ocpc_py import MultiClassPC\n",
    "from codecarbon import EmissionsTracker\n",
    "import json\n",
    "import sys\n",
    "import io\n",
    "\n",
    "#Saving logs\n",
    "log_buffer = io.StringIO()\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = log_buffer\n",
    "\n",
    "\n",
    "# Configuration\n",
    "base_path = \"../data/infection\"\n",
    "image_size = (256, 256)\n",
    "\n",
    "# Load dataset\n",
    "dataset = []\n",
    "for class_name, label in zip([\"Aug-Positive\", \"Aug-Negative\"], [1, 0]):\n",
    "    folder = os.path.join(base_path, class_name)\n",
    "    for image_name in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, image_name)\n",
    "        dataset.append((image_path, label))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=[\"image\", \"label\"])\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(df, image_size):\n",
    "    images, labels = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        img = cv2.imread(row[\"image\"])\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, image_size)\n",
    "            img = img.astype(\"float32\") / 255.0\n",
    "            images.append(img.flatten())\n",
    "            labels.append(row[\"label\"])\n",
    "        else:\n",
    "            print(f\"Image not loaded: {row['image']}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_all, y_all = load_images(df, image_size)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "\n",
    "print(\"\\n[Cross-Validation - Training]\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train), 1):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # PCA transformation\n",
    "    pca = PCA(n_components=50)\n",
    "    X_tr_pca = pca.fit_transform(X_tr)\n",
    "    X_val_pca = pca.transform(X_val)\n",
    "\n",
    "    # Train classifier\n",
    "    clf = MultiClassPC()\n",
    "    clf.fit(X_tr_pca, y_tr)\n",
    "    y_pred = clf.predict(X_val_pca)\n",
    "    y_proba = clf.predict_proba(X_val_pca)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    accs.append(accuracy_score(y_val, y_pred))\n",
    "    precs.append(precision_score(y_val, y_pred))\n",
    "    recs.append(recall_score(y_val, y_pred))\n",
    "    f1s.append(f1_score(y_val, y_pred))\n",
    "    aucs.append(roc_auc_score(y_val, y_proba))\n",
    "\n",
    "# Average metrics across folds\n",
    "print(\"\\n[Average Metrics - Cross-Validation]\")\n",
    "print(f\"Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "print(f\"Precision: {np.mean(precs):.4f} ± {np.std(precs):.4f}\")\n",
    "print(f\"Recall:   {np.mean(recs):.4f} ± {np.std(recs):.4f}\")\n",
    "print(f\"F1-Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "print(f\"AUC:      {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
    "\n",
    "# Final training and test evaluation\n",
    "print(\"\\n[Final Training and Test Evaluation]\")\n",
    "tracker = EmissionsTracker(log_level=\"ERROR\")\n",
    "tracker.start()\n",
    "\n",
    "# Final PCA transformation\n",
    "pca_final = PCA(n_components=50)\n",
    "X_train_pca = pca_final.fit_transform(X_train)\n",
    "X_test_pca = pca_final.transform(X_test)\n",
    "\n",
    "# Train final classifier\n",
    "clf_final = MultiClassPC()\n",
    "clf_final.fit(X_train_pca, y_train)\n",
    "\n",
    "# Stop carbon tracker and save emissions\n",
    "emissions = tracker.stop()\n",
    "emissions_dir = \"../reports/emissions\"\n",
    "os.makedirs(emissions_dir, exist_ok=True)\n",
    "emissions_path = os.path.join(emissions_dir, \"OCPC_infection.json\")\n",
    "with open(emissions_path, \"w\") as f:\n",
    "    json.dump({\"emissions_kgCO2eq\": emissions}, f)\n",
    "\n",
    "print(f\"\\n[Carbon Footprint]\")\n",
    "print(f\"Estimated emissions during the experiment: {emissions:.6f} kg CO₂eq\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test = clf_final.predict(X_test_pca)\n",
    "y_proba_test = clf_final.predict_proba(X_test_pca)[:, 1]\n",
    "\n",
    "print(\"\\n[Test Set Performance]\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall:   {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"AUC:      {roc_auc_score(y_test, y_proba_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Save PCA and final model\n",
    "output_dir = \"../models/infection\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "pca_path = os.path.join(output_dir, \"OCPC_pca_infection.pkl\")\n",
    "clf_path = os.path.join(output_dir, \"OCPC_pca_model_infection.pkl\")\n",
    "joblib.dump(pca_final, pca_path)\n",
    "joblib.dump(clf_final, clf_path)\n",
    "\n",
    "#stdout\n",
    "sys.stdout = old_stdout\n",
    "log_text = log_buffer.getvalue()\n",
    "os.makedirs(\"../reports/metrics\", exist_ok=True)\n",
    "with open(\"../reports/metrics/OCPC_infection_log.txt\", \"w\") as f:\n",
    "    f.write(log_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54631a0",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec985eb0",
   "metadata": {},
   "source": [
    "## Random Forest without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf18d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "import joblib\n",
    "from codecarbon import EmissionsTracker\n",
    "import json\n",
    "import sys\n",
    "import io\n",
    "\n",
    "log_buffer = io.StringIO()\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = log_buffer\n",
    "\n",
    "# Configuration\n",
    "base_path = \"../data/infection\"\n",
    "image_size = (256, 256)\n",
    "\n",
    "# Load dataset\n",
    "dataset = []\n",
    "for class_name, label in zip([\"Aug-Positive\", \"Aug-Negative\"], [1, 0]):\n",
    "    folder = os.path.join(base_path, class_name)\n",
    "    for image_name in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, image_name)\n",
    "        dataset.append((image_path, label))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=[\"image\", \"label\"])\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(df, image_size):\n",
    "    images, labels = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        img = cv2.imread(row[\"image\"])\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, image_size)\n",
    "            img = img.astype(\"float32\") / 255.0\n",
    "            images.append(img.flatten())\n",
    "            labels.append(row[\"label\"])\n",
    "        else:\n",
    "            print(f\"Image not loaded: {row['image']}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_all, y_all = load_images(df, image_size)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "\n",
    "print(\"\\n[Cross-Validation - Training]\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # Train Random Forest classifier\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=20,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    y_pred = clf.predict(X_val)\n",
    "    y_proba = clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Compute metrics\n",
    "    accs.append(accuracy_score(y_val, y_pred))\n",
    "    precs.append(precision_score(y_val, y_pred))\n",
    "    recs.append(recall_score(y_val, y_pred))\n",
    "    f1s.append(f1_score(y_val, y_pred))\n",
    "    aucs.append(roc_auc_score(y_val, y_proba))\n",
    "\n",
    "# Average metrics across folds\n",
    "print(\"\\n[Average Metrics - Cross-Validation]\")\n",
    "print(f\"Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "print(f\"Precision: {np.mean(precs):.4f} ± {np.std(precs):.4f}\")\n",
    "print(f\"Recall:   {np.mean(recs):.4f} ± {np.std(recs):.4f}\")\n",
    "print(f\"F1-Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "print(f\"AUC:      {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
    "\n",
    "# Final training and test evaluation\n",
    "print(\"\\n[Final Training and Test Evaluation]\")\n",
    "tracker = EmissionsTracker(log_level=\"ERROR\")\n",
    "tracker.start()\n",
    "\n",
    "clf_final = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=20,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf_final.fit(X_train, y_train)\n",
    "\n",
    "# Stop carbon tracker and save emissions\n",
    "emissions = tracker.stop()\n",
    "emissions_dir = \"../reports/emissions\"\n",
    "os.makedirs(emissions_dir, exist_ok=True)\n",
    "emissions_path = os.path.join(emissions_dir, \"infection_rf.json\")\n",
    "with open(emissions_path, \"w\") as f:\n",
    "    json.dump({\"emissions_kgCO2eq\": emissions}, f)\n",
    "\n",
    "print(f\"\\n[Carbon Footprint]\")\n",
    "print(f\"Estimated emissions during training: {emissions:.6f} kg CO₂eq\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test = clf_final.predict(X_test)\n",
    "y_proba_test = clf_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n[Test Set Performance]\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall:   {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"AUC:      {roc_auc_score(y_test, y_proba_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Save final model\n",
    "output_dir = \"../models/infection\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "clf_path = os.path.join(output_dir, \"random_forest_infection.pkl\")\n",
    "joblib.dump(clf_final, clf_path)\n",
    "\n",
    "#stdout\n",
    "sys.stdout = old_stdout\n",
    "log_text = log_buffer.getvalue()\n",
    "os.makedirs(\"../reports/metrics\", exist_ok=True)\n",
    "with open(\"../reports/metrics/rf_infection_log.txt\", \"w\") as f:\n",
    "    f.write(log_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece9e30",
   "metadata": {},
   "source": [
    "## Random Forest with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeccee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from codecarbon import EmissionsTracker\n",
    "import joblib\n",
    "import sys\n",
    "import io\n",
    "\n",
    "log_buffer = io.StringIO()\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = log_buffer\n",
    "\n",
    "# Configuration\n",
    "base_path = \"../data/infection\"\n",
    "image_size = (256, 256)\n",
    "\n",
    "# Load dataset\n",
    "dataset = []\n",
    "for classe, label in zip([\"Aug-Positive\", \"Aug-Negative\"], [1, 0]):\n",
    "    pasta = os.path.join(base_path, classe)\n",
    "    for imagem in os.listdir(pasta):\n",
    "        caminho_imagem = os.path.join(pasta, imagem)\n",
    "        dataset.append((caminho_imagem, label))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=[\"imagem\", \"label\"])\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(df, image_size):\n",
    "    imagens, labels = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        img = cv2.imread(row[\"imagem\"])\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, image_size)\n",
    "            img = img.astype(\"float32\") / 255.0\n",
    "            imagens.append(img.flatten())\n",
    "            labels.append(row[\"label\"])\n",
    "        else:\n",
    "            print(f\"Imagem não carregada: {row['imagem']}\")\n",
    "    return np.array(imagens), np.array(labels)\n",
    "\n",
    "X_all, y_all = load_images(df, image_size)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "\n",
    "print(\"\\n[Cross-Validation - Training]\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    pca = PCA(n_components=50)\n",
    "    X_tr_pca = pca.fit_transform(X_tr)\n",
    "    X_val_pca = pca.transform(X_val)\n",
    "\n",
    "    # Train Random Forest classifier\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=20,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    clf.fit(X_tr_pca, y_tr)\n",
    "    y_pred = clf.predict(X_val_pca)\n",
    "    y_proba = clf.predict_proba(X_val_pca)[:, 1]\n",
    "\n",
    "    # Compute metrics\n",
    "    accs.append(accuracy_score(y_val, y_pred))\n",
    "    precs.append(precision_score(y_val, y_pred))\n",
    "    recs.append(recall_score(y_val, y_pred))\n",
    "    f1s.append(f1_score(y_val, y_pred))\n",
    "    aucs.append(roc_auc_score(y_val, y_proba))\n",
    "\n",
    "# Average metrics across folds\n",
    "print(\"\\n[Average Metrics - Cross-Validation]\")\n",
    "print(f\"Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "print(f\"Precision: {np.mean(precs):.4f} ± {np.std(precs):.4f}\")\n",
    "print(f\"Recall:   {np.mean(recs):.4f} ± {np.std(recs):.4f}\")\n",
    "print(f\"F1-Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "print(f\"AUC:      {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
    "\n",
    "# Final training and test evaluation\n",
    "print(\"\\n[Final Training and Test Evaluation]\")\n",
    "tracker = EmissionsTracker(log_level=\"ERROR\")\n",
    "tracker.start()\n",
    "\n",
    "pca_final = PCA(n_components=50)\n",
    "X_train_pca = pca_final.fit_transform(X_train)\n",
    "X_test_pca = pca_final.transform(X_test)\n",
    "\n",
    "clf_final = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=20,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf_final.fit(X_train_pca, y_train)\n",
    "\n",
    "# Stop carbon tracker and save emissions\n",
    "emissions = tracker.stop()\n",
    "emissions_dir = \"../reports/emissions\"\n",
    "os.makedirs(emissions_dir, exist_ok=True)\n",
    "emissions_path = os.path.join(emissions_dir, \"infection_rf(pca).json\")\n",
    "with open(emissions_path, \"w\") as f:\n",
    "    json.dump({\"emissions_kgCO2eq\": emissions}, f)\n",
    "\n",
    "print(f\"\\n[Carbon Footprint]\")\n",
    "print(f\"Estimated emissions during training: {emissions:.6f} kg CO₂eq\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test = clf_final.predict(X_test_pca)\n",
    "y_proba_test = clf_final.predict_proba(X_test_pca)[:, 1]\n",
    "\n",
    "print(\"\\n[Test Set Performance]\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall:   {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"AUC:      {roc_auc_score(y_test, y_proba_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Save final model\n",
    "output_dir = \"../models/infection\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "pca_path = os.path.join(output_dir, \"random_forest_PCA_infection.pkl\")\n",
    "clf_path = os.path.join(output_dir, \"random_forest_model_PCA_infection.pkl\")\n",
    "joblib.dump(pca_final, pca_path)\n",
    "joblib.dump(clf_final, clf_path)\n",
    "\n",
    "#stdout\n",
    "sys.stdout = old_stdout\n",
    "log_text = log_buffer.getvalue()\n",
    "os.makedirs(\"../reports/metrics\", exist_ok=True)\n",
    "with open(\"../reports/metrics/rf_pca_infection_log.txt\", \"w\") as f:\n",
    "    f.write(log_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf6d971",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de285d40",
   "metadata": {},
   "source": [
    "## XGBOOST with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251efce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from codecarbon import EmissionsTracker\n",
    "import sys\n",
    "import io\n",
    "\n",
    "log_buffer = io.StringIO()\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = log_buffer\n",
    "\n",
    "# Configuration\n",
    "base_path = \"../data/infection\"\n",
    "image_size = (256, 256)\n",
    "\n",
    "# Load dataset\n",
    "dataset = []\n",
    "for classe, label in zip([\"Aug-Positive\", \"Aug-Negative\"], [1, 0]):\n",
    "    pasta = os.path.join(base_path, classe)\n",
    "    for imagem in os.listdir(pasta):\n",
    "        caminho_imagem = os.path.join(pasta, imagem)\n",
    "        dataset.append((caminho_imagem, label))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=[\"imagem\", \"label\"])\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(df, image_size):\n",
    "    imagens, labels = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        img = cv2.imread(row[\"imagem\"])\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, image_size)\n",
    "            img = img.astype(\"float32\") / 255.0\n",
    "            imagens.append(img.flatten())\n",
    "            labels.append(row[\"label\"])\n",
    "        else:\n",
    "            print(f\"Imagem não carregada: {row['imagem']}\")\n",
    "    return np.array(imagens), np.array(labels)\n",
    "\n",
    "X_all, y_all = load_images(df, image_size)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "\n",
    "print(\"\\n[Cross-Validation - Training]\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    pca = PCA(n_components=50)\n",
    "    X_tr_pca = pca.fit_transform(X_tr)\n",
    "    X_val_pca = pca.transform(X_val)\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    eval_metric='logloss',\n",
    "    tree_method=\"hist\",  \n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "    clf.fit(X_tr_pca, y_tr)\n",
    "\n",
    "    y_pred = clf.predict(X_val_pca)\n",
    "    y_proba = clf.predict_proba(X_val_pca)[:, 1]\n",
    "\n",
    "    accs.append(accuracy_score(y_val, y_pred))\n",
    "    precs.append(precision_score(y_val, y_pred))\n",
    "    recs.append(recall_score(y_val, y_pred))\n",
    "    f1s.append(f1_score(y_val, y_pred))\n",
    "    aucs.append(roc_auc_score(y_val, y_proba))\n",
    "\n",
    "# Average metrics across folds\n",
    "print(\"\\n[Average Metrics - Cross-Validation]\")\n",
    "print(f\"Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "print(f\"Precision: {np.mean(precs):.4f} ± {np.std(precs):.4f}\")\n",
    "print(f\"Recall:   {np.mean(recs):.4f} ± {np.std(recs):.4f}\")\n",
    "print(f\"F1-Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "print(f\"AUC:      {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
    "\n",
    "# Final training and test evaluation\n",
    "print(\"\\n[Final Training and Test Evaluation]\")\n",
    "tracker = EmissionsTracker(log_level=\"ERROR\")\n",
    "tracker.start()\n",
    "\n",
    "pca_final = PCA(n_components=50)\n",
    "X_train_pca = pca_final.fit_transform(X_train)\n",
    "X_test_pca = pca_final.transform(X_test)\n",
    "\n",
    "clf_final = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    eval_metric='logloss',\n",
    "    tree_method=\"hist\",  \n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf_final.fit(X_train_pca, y_train)\n",
    "\n",
    "# Stop carbon tracker and save emissions\n",
    "emissions = tracker.stop()\n",
    "emissions_dir = \"../reports/emissions\"\n",
    "os.makedirs(emissions_dir, exist_ok=True)\n",
    "emissions_path = os.path.join(emissions_dir, \"infection_xgb(pca).json\")\n",
    "with open(emissions_path, \"w\") as f:\n",
    "    json.dump({\"emissions_kgCO2eq\": emissions}, f)\n",
    "\n",
    "print(f\"\\n[Carbon Footprint]\")\n",
    "print(f\"Estimated emissions during training: {emissions:.6f} kg CO₂eq\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test = clf_final.predict(X_test_pca)\n",
    "y_proba_test = clf_final.predict_proba(X_test_pca)[:, 1]\n",
    "\n",
    "print(\"\\n[Test Set Performance]\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall:   {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"AUC:      {roc_auc_score(y_test, y_proba_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Save final model\n",
    "output_dir = \"../models/infection\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "pca_path = os.path.join(output_dir, \"xgboost_PCA_infection.pkl\")\n",
    "clf_path = os.path.join(output_dir, \"xgboost_model_PCA_infection.pkl\")\n",
    "joblib.dump(pca_final, pca_path)\n",
    "joblib.dump(clf_final, clf_path)\n",
    "\n",
    "#stdout\n",
    "sys.stdout = old_stdout\n",
    "log_text = log_buffer.getvalue()\n",
    "os.makedirs(\"../reports/metrics\", exist_ok=True)\n",
    "with open(\"../reports/metrics/xgb_pca_infection_log.txt\", \"w\") as f:\n",
    "    f.write(log_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1357c9",
   "metadata": {},
   "source": [
    "## XGBOOST without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5ac1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from codecarbon import EmissionsTracker\n",
    "import sys\n",
    "import io\n",
    "\n",
    "log_buffer = io.StringIO()\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = log_buffer\n",
    "\n",
    "# Configuration\n",
    "base_path = \"../data/infection\"\n",
    "image_size = (256, 256)\n",
    "\n",
    "# Load dataset\n",
    "dataset = []\n",
    "for classe, label in zip([\"Aug-Positive\", \"Aug-Negative\"], [1, 0]):\n",
    "    pasta = os.path.join(base_path, classe)\n",
    "    for imagem in os.listdir(pasta):\n",
    "        dataset.append((os.path.join(pasta, imagem), label))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=[\"imagem\", \"label\"])\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(df, image_size):\n",
    "    imagens, labels = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        img = cv2.imread(row[\"imagem\"])\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, image_size)\n",
    "            img = img.astype(\"float32\") / 255.0\n",
    "            imagens.append(img.flatten())\n",
    "            labels.append(row[\"label\"])\n",
    "        else:\n",
    "            print(f\"Imagem não carregada: {row['imagem']}\")\n",
    "    return np.array(imagens), np.array(labels)\n",
    "\n",
    "X_all, y_all = load_images(df, image_size)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "\n",
    "print(\"\\n[Cross-Validation - Training]\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    eval_metric='logloss',\n",
    "    tree_method=\"hist\",  \n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    "    )\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    y_pred = clf.predict(X_val)\n",
    "    y_proba = clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    accs.append(accuracy_score(y_val, y_pred))\n",
    "    precs.append(precision_score(y_val, y_pred))\n",
    "    recs.append(recall_score(y_val, y_pred))\n",
    "    f1s.append(f1_score(y_val, y_pred))\n",
    "    aucs.append(roc_auc_score(y_val, y_proba))\n",
    "\n",
    "# Average metrics across folds\n",
    "print(\"\\n[Average Metrics - Cross-Validation]\")\n",
    "print(f\"Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "print(f\"Precision: {np.mean(precs):.4f} ± {np.std(precs):.4f}\")\n",
    "print(f\"Recall:   {np.mean(recs):.4f} ± {np.std(recs):.4f}\")\n",
    "print(f\"F1-Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "print(f\"AUC:      {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
    "\n",
    "# Final training and test evaluation\n",
    "print(\"\\n[Final Training and Test Evaluation]\")\n",
    "tracker = EmissionsTracker(log_level=\"ERROR\")\n",
    "tracker.start()\n",
    "\n",
    "clf_final = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    eval_metric='logloss',\n",
    "    tree_method=\"hist\",  \n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf_final.fit(X_train, y_train)\n",
    "\n",
    "# Stop carbon tracker and save emissions\n",
    "emissions = tracker.stop()\n",
    "emissions_dir = \"../reports/emissions\"\n",
    "os.makedirs(emissions_dir, exist_ok=True)\n",
    "emissions_path = os.path.join(emissions_dir, \"infection_xgb.json\")\n",
    "with open(emissions_path, \"w\") as f:\n",
    "    json.dump({\"emissions_kgCO2eq\": emissions}, f)\n",
    "\n",
    "print(f\"\\n[Carbon Footprint]\")\n",
    "print(f\"Estimated emissions during training: {emissions:.6f} kg CO₂eq\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test = clf_final.predict(X_test)\n",
    "y_proba_test = clf_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n[Test Set Performance]\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall:   {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"AUC:      {roc_auc_score(y_test, y_proba_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Save final model\n",
    "output_dir = \"../models/infection\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "clf_path = os.path.join(output_dir, \"xgboost_infection.pkl\")\n",
    "joblib.dump(clf_final, clf_path)\n",
    "\n",
    "#stdout\n",
    "sys.stdout = old_stdout\n",
    "log_text = log_buffer.getvalue()\n",
    "os.makedirs(\"../reports/metrics\", exist_ok=True)\n",
    "with open(\"../reports/metrics/xgb_infection_log.txt\", \"w\") as f:\n",
    "    f.write(log_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40af35a",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70871b1",
   "metadata": {},
   "source": [
    "## MLP with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from codecarbon import EmissionsTracker\n",
    "import sys\n",
    "import io\n",
    "\n",
    "log_buffer = io.StringIO()\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = log_buffer\n",
    "\n",
    "# Configuration\n",
    "base_path = \"../data/infection\"\n",
    "image_size = (256, 256)\n",
    "\n",
    "# Load dataset\n",
    "dataset = []\n",
    "for classe, label in zip([\"Aug-Positive\", \"Aug-Negative\"], [1, 0]):\n",
    "    pasta = os.path.join(base_path, classe)\n",
    "    for imagem in os.listdir(pasta):\n",
    "        caminho_imagem = os.path.join(pasta, imagem)\n",
    "        dataset.append((caminho_imagem, label))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=[\"imagem\", \"label\"])\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(df, image_size):\n",
    "    imagens, labels = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        img = cv2.imread(row[\"imagem\"])\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, image_size)\n",
    "            img = img.astype(\"float32\") / 255.0\n",
    "            imagens.append(img.flatten())\n",
    "            labels.append(row[\"label\"])\n",
    "        else:\n",
    "            print(f\"Imagem não carregada: {row['imagem']}\")\n",
    "    return np.array(imagens), np.array(labels)\n",
    "\n",
    "X_all, y_all = load_images(df, image_size)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "\n",
    "print(\"\\n[Cross-Validation - Training]\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    pca = PCA(n_components=50)\n",
    "    X_tr_pca = pca.fit_transform(X_tr)\n",
    "    X_val_pca = pca.transform(X_val)\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 64),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=1e-4,\n",
    "        learning_rate_init=0.001,\n",
    "        max_iter=500,\n",
    "        early_stopping=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_tr_pca, y_tr)\n",
    "\n",
    "    y_pred = clf.predict(X_val_pca)\n",
    "    y_proba = clf.predict_proba(X_val_pca)[:, 1]\n",
    "\n",
    "    accs.append(accuracy_score(y_val, y_pred))\n",
    "    precs.append(precision_score(y_val, y_pred))\n",
    "    recs.append(recall_score(y_val, y_pred))\n",
    "    f1s.append(f1_score(y_val, y_pred))\n",
    "    aucs.append(roc_auc_score(y_val, y_proba))\n",
    "\n",
    "# Average metrics across folds\n",
    "print(\"\\n[Average Metrics - Cross-Validation]\")\n",
    "print(f\"Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "print(f\"Precision: {np.mean(precs):.4f} ± {np.std(precs):.4f}\")\n",
    "print(f\"Recall:   {np.mean(recs):.4f} ± {np.std(recs):.4f}\")\n",
    "print(f\"F1-Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "print(f\"AUC:      {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
    "\n",
    "# Final training and test evaluation\n",
    "print(\"\\n[Final Training and Test Evaluation]\")\n",
    "tracker = EmissionsTracker(log_level=\"ERROR\")\n",
    "tracker.start()\n",
    "\n",
    "pca_final = PCA(n_components=50)\n",
    "X_train_pca = pca_final.fit_transform(X_train)\n",
    "X_test_pca = pca_final.transform(X_test)\n",
    "\n",
    "clf_final = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=1e-4,\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    random_state=42\n",
    ")\n",
    "clf_final.fit(X_train_pca, y_train)\n",
    "\n",
    "# Stop carbon tracker and save emissions\n",
    "emissions = tracker.stop()\n",
    "emissions_dir = \"../reports/emissions\"\n",
    "os.makedirs(emissions_dir, exist_ok=True)\n",
    "emissions_path = os.path.join(emissions_dir, \"infection_mlp(pca).json\")\n",
    "with open(emissions_path, \"w\") as f:\n",
    "    json.dump({\"emissions_kgCO2eq\": emissions}, f)\n",
    "\n",
    "print(f\"\\n[Carbon Footprint]\")\n",
    "print(f\"Estimated emissions during training: {emissions:.6f} kg CO₂eq\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test = clf_final.predict(X_test_pca)\n",
    "y_proba_test = clf_final.predict_proba(X_test_pca)[:, 1]\n",
    "\n",
    "print(\"\\n[Test Set Performance]\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall:   {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"AUC:      {roc_auc_score(y_test, y_proba_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Save final model\n",
    "output_dir = \"../models/infection\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "pca_path = os.path.join(output_dir, \"mlp_PCA_infection.pkl\")\n",
    "clf_path = os.path.join(output_dir, \"mlp_model_PCA_infection.pkl\")\n",
    "joblib.dump(pca_final, pca_path)\n",
    "joblib.dump(clf_final, clf_path)\n",
    "\n",
    "#stdout\n",
    "sys.stdout = old_stdout\n",
    "log_text = log_buffer.getvalue()\n",
    "os.makedirs(\"../reports/metrics\", exist_ok=True)\n",
    "with open(\"../reports/metrics/mlp_pca_infection_log.txt\", \"w\") as f:\n",
    "    f.write(log_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d656bec",
   "metadata": {},
   "source": [
    "## MLP without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ff911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from codecarbon import EmissionsTracker\n",
    "import sys\n",
    "import io\n",
    "\n",
    "log_buffer = io.StringIO()\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = log_buffer\n",
    "\n",
    "# Configuration\n",
    "base_path = \"../data/infection\"\n",
    "image_size = (256, 256)\n",
    "\n",
    "# Load dataset\n",
    "dataset = []\n",
    "for classe, label in zip([\"Aug-Positive\", \"Aug-Negative\"], [1, 0]):\n",
    "    pasta = os.path.join(base_path, classe)\n",
    "    for imagem in os.listdir(pasta):\n",
    "        dataset.append((os.path.join(pasta, imagem), label))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=[\"imagem\", \"label\"])\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(df, image_size):\n",
    "    imagens, labels = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        img = cv2.imread(row[\"imagem\"])\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, image_size)\n",
    "            img = img.astype(\"float32\") / 255.0\n",
    "            imagens.append(img.flatten())\n",
    "            labels.append(row[\"label\"])\n",
    "        else:\n",
    "            print(f\"Imagem não carregada: {row['imagem']}\")\n",
    "    return np.array(imagens), np.array(labels)\n",
    "\n",
    "X_all, y_all = load_images(df, image_size)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, precs, recs, f1s, aucs = [], [], [], [], []\n",
    "\n",
    "print(\"\\n[Cross-Validation - Training]\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 64),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=1e-4,\n",
    "        learning_rate_init=0.001,\n",
    "        max_iter=500,\n",
    "        early_stopping=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    y_pred = clf.predict(X_val)\n",
    "    y_proba = clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    accs.append(accuracy_score(y_val, y_pred))\n",
    "    precs.append(precision_score(y_val, y_pred))\n",
    "    recs.append(recall_score(y_val, y_pred))\n",
    "    f1s.append(f1_score(y_val, y_pred))\n",
    "    aucs.append(roc_auc_score(y_val, y_proba))\n",
    "\n",
    "# Average metrics across folds\n",
    "print(\"\\n[Average Metrics - Cross-Validation]\")\n",
    "print(f\"Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "print(f\"Precision: {np.mean(precs):.4f} ± {np.std(precs):.4f}\")\n",
    "print(f\"Recall:   {np.mean(recs):.4f} ± {np.std(recs):.4f}\")\n",
    "print(f\"F1-Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "print(f\"AUC:      {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
    "\n",
    "# Final training and test evaluation\n",
    "print(\"\\n[Final Training and Test Evaluation]\")\n",
    "tracker = EmissionsTracker(log_level=\"ERROR\")\n",
    "tracker.start()\n",
    "\n",
    "clf_final = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=1e-4,\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    random_state=42\n",
    ")\n",
    "clf_final.fit(X_train, y_train)\n",
    "\n",
    "# Stop carbon tracker and save emissions\n",
    "emissions = tracker.stop()\n",
    "emissions_dir = \"../reports/emissions\"\n",
    "os.makedirs(emissions_dir, exist_ok=True)\n",
    "emissions_path = os.path.join(emissions_dir, \"infection_mlp.json\")\n",
    "with open(emissions_path, \"w\") as f:\n",
    "    json.dump({\"emissions_kgCO2eq\": emissions}, f)\n",
    "\n",
    "print(f\"\\n[Carbon Footprint]\")\n",
    "print(f\"Estimated emissions during training: {emissions:.6f} kg CO₂eq\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test = clf_final.predict(X_test)\n",
    "y_proba_test = clf_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n[Test Set Performance]\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall:   {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"AUC:      {roc_auc_score(y_test, y_proba_test):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Save final model\n",
    "output_dir = \"../models/infection\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "clf_path = os.path.join(output_dir, \"mlp_infection.pkl\")\n",
    "joblib.dump(clf_final, clf_path)\n",
    "\n",
    "#stdout\n",
    "sys.stdout = old_stdout\n",
    "log_text = log_buffer.getvalue()\n",
    "os.makedirs(\"../reports/metrics\", exist_ok=True)\n",
    "with open(\"../reports/metrics/mlp_infection_log.txt\", \"w\") as f:\n",
    "    f.write(log_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
